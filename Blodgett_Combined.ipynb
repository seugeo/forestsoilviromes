{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dereplication of Blodgett2021 and Heat 2022 viral contigs combined\n",
    "\n",
    "cd ~/blodgett_combined\n",
    "\n",
    "# starting input files\n",
    "blodgett2021.vib.contigs.fna\n",
    "    # count how many total contigs\n",
    "    grep -c contig blodgett2021.vib.contigs.fna\n",
    "    # 327,006 contigs \n",
    "heat2022.vib.contigs.fna\n",
    "    # count how many total contigs\n",
    "    grep -c contig heat2022.vib.contigs.fna\n",
    "    # 141,638 contigs\n",
    "    # I already ran CDHIT on this, so I'm just going to combine the output with blodgett output once I get that\n",
    "    clustered_heat.fna\n",
    "    # 34,948 contigs\n",
    "    \n",
    "# make cdhit directory\n",
    "mkdir cdhit\n",
    "\n",
    "# cluster blodgett alone using CD HIT\n",
    "# rename file to use for CD Hit (input.fna)\n",
    "cp blodgett2021.vib.contigs.fna ./input.fna\n",
    "\n",
    "# create CD HIT script\n",
    "nano cdhitblodgett21.sh\n",
    "\n",
    "-----------------\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=cdhit\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH -t 24:00:00\n",
    "#SBATCH --ntasks=10\n",
    "#SBATCH --output=cdhit%j.out\n",
    "#SBATCH --error=cdhit%j.err\n",
    "#SBATCH --partition=bmh\n",
    "\n",
    "module load cdhit\n",
    "cd-hit-est -i input.fna -o clustered_blodgett.fna \\\n",
    "-c 0.95 -aS 0.85 -M 14000 -T 10\n",
    "-----------------\n",
    "\n",
    "# run CD HIT script for blodgett21 contigs\n",
    "sbatch --output=./log/blodgett21.log --error=./err/blodgett21.err cdhitblodgett21.sh\n",
    "\n",
    "# number of contigs after CD HIT: 327,006 --> 242,971\n",
    "\n",
    "# combine CD HIT outputs from both experiments and then run CD HIT together\n",
    "cat clustered* > blodgett2122.vib.contigs.fna \n",
    "\n",
    "\n",
    "# calculate total number of contigs before final CD HIT: \n",
    "grep -c contig blodgett2122.vib.contigs.fna\n",
    "# total contigs = 277,919\n",
    "\n",
    "# rename file to use for CD Hit (input.fna)\n",
    "cp blodgett2122.vib.contigs.fna ./input.fna\n",
    "\n",
    "# create CD HIT script\n",
    "nano cdhit.sh\n",
    "\n",
    "-----------------\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=cdhit\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH -t 24:00:00\n",
    "#SBATCH --ntasks=10\n",
    "#SBATCH --output=cdhit%j.out\n",
    "#SBATCH --error=cdhit%j.err\n",
    "#SBATCH --partition=bmh\n",
    "\n",
    "module load cdhit\n",
    "cd-hit-est -i input.fna -o clustered_all.fna \\\n",
    "-c 0.95 -aS 0.85 -M 15000 -T 10\n",
    "-----------------\n",
    "\n",
    "# run CD HIT on all contigs\n",
    "sbatch --output=./log/all.log --error=./err/all.err cdhit.sh\n",
    "\n",
    "# number of contigs after CD HIT\n",
    "grep -c contig clustered_all.fna\n",
    "    # 277,919 --> 272,017\n",
    "\n",
    "# now run dereplication\n",
    "\n",
    "# take the concatenated file and move it to the appropriate split_contig folder within a drep/\"subset\"/split_contigs\n",
    "mv clustered_all.fna ../drep/all/split_contigs\n",
    "\n",
    "# separate the concatenated fasta file into multiple ones\n",
    "# use screen because this will take awhile...\n",
    "screen\n",
    "cd ~/blodgett_combined/drep/all/split_contigs\n",
    "awk '/^>/ {OUT=substr($0,2) \".fa\"}; OUT {print >OUT}' *.fna \n",
    "    # if using screen...you can monitor how close it is to done by counting file names\n",
    "        ls -1 | wc -l        \n",
    "# detach from screen: ctrl a + d\n",
    "# to see screens running\n",
    "screen -r\n",
    "# to end screen\n",
    "exit\n",
    "\n",
    "# once done, remove the concatenated file from folder (you can move up a folder)\n",
    "mv clustered_all.fna ../\n",
    "\n",
    "# divide contigs into ~ six batches \n",
    "mkdir batch1 batch2 batch3 batch4 batch5 batch6\n",
    "\n",
    "# within each batch, make a split_contigs folder\n",
    "cd batch1\n",
    "mkdir split_contigs\n",
    "\n",
    "# because 272,017 is too many for one run of drep, it will run out of memory\n",
    "# each batch needs to be less than 50,000, so divide into 6 batches\n",
    "cd all/split_contigs\n",
    "ls | head -n 45337 | xargs -I {} mv {} ../../batch1/split_contigs\n",
    "ls | head -n 45337 | xargs -I {} mv {} ../../batch2/split_contigs\n",
    "ls | head -n 45337 | xargs -I {} mv {} ../../batch3/split_contigs\n",
    "ls | head -n 45337 | xargs -I {} mv {} ../../batch4/split_contigs\n",
    "ls | head -n 45337 | xargs -I {} mv {} ../../batch5/split_contigs\n",
    "ls | head -n 45332 | xargs -I {} mv {} ../../batch6/split_contigs\n",
    "\n",
    "\n",
    "# make drep script\n",
    "nano drep.sh\n",
    "-----------------------------------------------------------------------------------------\n",
    "\n",
    "#!/bin/bash\n",
    "#SBATCH -D /home/seuge91/blodgett_combined/drep\n",
    "#SBATCH --job-name=drep\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH -t 72:00:00\n",
    "#SBATCH --ntasks=24\n",
    "#SBATCH --mem=900GB\n",
    "#SBATCH --partition=bmh\n",
    "\n",
    "# for calculating the amount of time the job takes\n",
    "begin=`date +%s`\n",
    "echo $HOSTNAME\n",
    "\n",
    "# activate personal conda env\n",
    "source /home/csantosm/initconda\n",
    "conda activate DREP\n",
    "\n",
    "treatment=${1}\n",
    "\n",
    "cd /home/seuge91/blodgett_combined/drep/${treatment}\n",
    "\n",
    "dRep dereplicate ./${treatment}_dRep \\\n",
    "-g ./split_contigs/*.fa \\\n",
    "--S_algorithm ANImf \\\n",
    "-sa 0.95 \\\n",
    "-nc 0.85 \\\n",
    "-l 10000 \\\n",
    "-N50W 0 \\\n",
    "-sizeW 1 \\\n",
    "--ignoreGenomeQuality \\\n",
    "--clusterAlg single \\\n",
    "-p 24\n",
    "\n",
    "#getting end time to calculate time elapsed\n",
    "end=`date +%s`\n",
    "elapsed=`expr $end - $begin`\n",
    "echo Time taken: $elapsed\n",
    "    \n",
    "-----------------------------------------------------------------------------------------\n",
    "# run the script giving the variable of the subset folder that has the split_contigs directory\n",
    "sbatch drep.sh batch1\n",
    "sbatch drep.sh batch2\n",
    "sbatch drep.sh batch3\n",
    "sbatch drep.sh batch4\n",
    "sbatch drep.sh batch5\n",
    "sbatch drep.sh batch6\n",
    "-----------------------------------------------------------------------------------------\n",
    "\n",
    "# number of contigs after drep: ?? --> ?? \n",
    "# batch1: 45337 --> 42431 \n",
    "# batch2: 45337 --> 42230\n",
    "\n",
    "# this is not enough reduction to keep running depreplication...\n",
    "# so for now, I'm just moving forward with clustering from CD HIT alone\n",
    "\n",
    "# how to download the CD HIT output file\n",
    "scp seuge91@farm.cse.ucdavis.edu:/home/seuge91/blodgett_combined/cdhit/output/clustered_all.fna.clstr /mnt/c/Users/segeo/Downloads\n",
    "    \n",
    "# figuring out nucleotides of the renamed_contigs \n",
    "# none of these commands worked!\n",
    "# the reason I'm doing this is to figure out which of the heat tolerant contigs identified in the heating study\n",
    "# could be identified in blodgett prescribed burn and in what samples and at what abundance\n",
    "# the problem is, since I dereplicated them all together, the contig name used in the heat study might have been clustered under\n",
    "# a different name (the contig assembled from the prescribed burn study might be the one that is representing the cluster)\n",
    "# So, I need to identify which contigs were renamed, but the other problem is the CD HIT output file doesn't actually have the \n",
    "# full name of the contigs that are clustered together (the contig names are too long, and so they get cut off), \n",
    "# so I can't identify it simply. The only way I can do it is by looking at \n",
    "# nucleotide number since the output file has that information, so that's what I've been trying to do, pull out the specific\n",
    "# contigs from the input file and then calculate the number of nucleotides associated with each contig, but\n",
    "# none of these commands are working!!!\n",
    "\n",
    "\n",
    "grep -A 1 -f renamed_contigs.txt input.fna | grep -v \"^--$\" > selected_contigs.fasta\n",
    "\n",
    "grep -F -f renamed_contigs.txt -A 1 input.fna | grep -v \"^--$\" > selected_contigs.fasta\n",
    "\n",
    "awk 'NR==FNR{a[$0];next} /^>/{p=($1 in a)} p' renamed_contigs.txt input.fna > selected_contigs.fasta\n",
    "\n",
    "\n",
    "# I'm going to rerun the final CD-HIT but change the output file so that it doesn't cut off the contig name. (add -d ?)\n",
    "# Then I will need to see if the .clstr file is the exact same as the original .clstr file \n",
    "\n",
    "# create new CD HIT script\n",
    "nano new_cdhit.sh\n",
    "\n",
    "-----------------\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=new_cdhit\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH -t 24:00:00\n",
    "#SBATCH --ntasks=10\n",
    "#SBATCH --output=new_cdhit%j.out\n",
    "#SBATCH --error=new_cdhit%j.err\n",
    "#SBATCH --partition=bmh\n",
    "\n",
    "module load cdhit\n",
    "cd-hit-est -i input.fna -o clustered_all_new.fna \\\n",
    "-c 0.95 -aS 0.85 -d 0 -M 15000 -T 10\n",
    "-----------------\n",
    "\n",
    "# run CD HIT on all contigs\n",
    "sbatch --output=./log/new_all.log --error=./err/new_all.err new_cdhit.sh\n",
    "\n",
    "# to see if the output files are identical\n",
    "diff -q clustered_all.fna clustered_all_new.fna\n",
    "\n",
    "# yes! Identical!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read mapping\n",
    "\n",
    "# make the directory structure for bowtie\n",
    "mkdir bowtie\n",
    "cd bowtie\n",
    "mkdir err log alignments ref coverm\n",
    "\n",
    "# input will be final CD HIT file\n",
    "drep/all/clustered_all.fna\n",
    "\n",
    "# convert this to a .fa file\n",
    "cp clustered_all.fna clustered_all.fa\n",
    "\n",
    "# make bowtie reference script\n",
    "nano bowtie_ref.sh\n",
    "\n",
    "# I needed to increase memory to 200GB because such a large dataset...\n",
    "----------------------------\n",
    "\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=bt2ref\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH -t 12:00:00\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --mem=200GB\n",
    "#SBATCH --partition=bmh\n",
    "\n",
    "# for calculating the amount of time the job takes\n",
    "begin=`date +%s`\n",
    "echo $HOSTNAME\n",
    "\n",
    "module load bowtie2\n",
    "\n",
    "cd /home/seuge91/blodgett_combined/bowtie/ref/\n",
    "\n",
    "bowtie2-build ../clustered_all.fa all_vibrant_cdhit\n",
    "\n",
    "# getting end time to calculate time elapsed\n",
    "end=`date +%s`\n",
    "elapsed=`expr $end - $begin`\n",
    "echo Time taken: $elapsed\n",
    "    \n",
    "----------------------------\n",
    "\n",
    "# run the script to index the reference database\n",
    "sbatch --output=../bowtie/log/ref.log --error=../bowtie/err/ref.err bowtie_ref.sh\n",
    "\n",
    "# map the reads against the database\n",
    "# make mapping script\n",
    "nano bowtie_map.sh\n",
    "\n",
    "----------------------------\n",
    "\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=bt2map\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH -t 6:00:00\n",
    "#SBATCH --ntasks=48\n",
    "#SBATCH --partition=bmh\n",
    "\n",
    "# for calculating the amount of time the job takes\n",
    "begin=`date +%s`\n",
    "echo $HOSTNAME\n",
    "\n",
    "#load modules\n",
    "module load bowtie2\n",
    "module load samtools\n",
    "\n",
    "path=/home/seuge91/blodgett_combined/\n",
    "sample=${1}\n",
    "\n",
    "cd /home/seuge91/blodgett_combined/bowtie/ref/\n",
    "\n",
    "bowtie2 -x all_vibrant_cdhit -p 48 \\\n",
    "-1 ${path}reads/rmphix/${sample}_R1_rmphix.fq.gz \\\n",
    "-2 ${path}reads/rmphix/${sample}_R2_rmphix.fq.gz \\\n",
    "-S ${path}bowtie/alignments/${sample}.vib.sam \\\n",
    "--sensitive\n",
    "\n",
    "cd /home/seuge91/blodgett_combined/bowtie/alignments\n",
    "samtools view -F 4 -bS ${sample}.vib.sam | samtools sort > ${sample}.vib.sI.bam\n",
    "samtools index ${sample}.vib.sI.bam\n",
    "\n",
    "rm ${sample}.vib.sam\n",
    "\n",
    "# getting end time to calculate time elapsed\n",
    "end=`date +%s`\n",
    "elapsed=`expr $end - $begin`\n",
    "echo Time taken: $elapsed\n",
    "    \n",
    "----------------------------\n",
    "\n",
    "# edit file names first:\n",
    "for file in *_rmphix_combined.fq.gz; do mv \"$file\" \"${file/_combined/}\"; done\n",
    "\n",
    "# run mapping script\n",
    "for sample in $(<../all_sample.txt)\n",
    "do\n",
    "  sbatch --output=../bowtie/log/${sample}.map.log --error=../bowtie/err/${sample}.map.err bowtie_map.sh $sample\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate vOTU table\n",
    "\n",
    "# make coverM script\n",
    "nano coverm.sh\n",
    "\n",
    "----------------------------\n",
    "\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=coverm\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH -t 10:00:00\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --partition=bmh\n",
    "\n",
    "# for calculating the amount of time the job takes\n",
    "begin=`date +%s`\n",
    "echo $HOSTNAME\n",
    "\n",
    "## you need to run the command from my coverm folder\n",
    "cd /home/csantosm/software/coverm-x86_64-unknown-linux-musl-0.6.1/\n",
    "\n",
    "path=/home/seuge91/blodgett_combined/bowtie/\n",
    "\n",
    "./coverm contig -m trimmed_mean --min-covered-fraction 0.75 -b ${path}/alignments/*.bam > ${path}/coverm/all.good.75.tmean.tsv\n",
    "\n",
    "# getting end time to calculate time elapsed\n",
    "end=`date +%s`\n",
    "elapsed=`expr $end - $begin`\n",
    "echo Time taken: $elapsed\n",
    "    \n",
    "----------------------------\n",
    "\n",
    "# run script\n",
    "sbatch --output=../bowtie/log/coverm.log --output=../bowtie/err/coverm.err coverm.sh\n",
    "\n",
    "# download table\n",
    "\n",
    "scp seuge91@farm.cse.ucdavis.edu:/home/seuge91/blodgett_combined/bowtie/coverm/*.tsv /mnt/c/Users/segeo/Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Count Table for Differential Abundance\n",
    "\n",
    "# make covermcount script\n",
    "nano covermcount.sh\n",
    "\n",
    "----------------------------\n",
    "\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=covermcount\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH -t 10:00:00\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --partition=bmh\n",
    "\n",
    "# for calculating the amount of time the job takes\n",
    "begin=`date +%s`\n",
    "echo $HOSTNAME\n",
    "\n",
    "## you need to run the command from my coverm folder\n",
    "cd /home/csantosm/software/coverm-x86_64-unknown-linux-musl-0.6.1/\n",
    "\n",
    "path=/home/seuge91/blodgett_combined/bowtie/\n",
    "\n",
    "./coverm contig -m count -b ${path}/alignments/*.bam > ${path}/coverm/all.count.tsv\n",
    "\n",
    "# getting end time to calculate time elapsed\n",
    "end=`date +%s`\n",
    "elapsed=`expr $end - $begin`\n",
    "echo Time taken: $elapsed\n",
    "        \n",
    "----------------------------\n",
    "    \n",
    "# Download table\n",
    "    \n",
    "scp seuge91@farm.cse.ucdavis.edu:/home/seuge91/heat/bowtie/coverm/*.count.tsv /mnt/c/Users/segeo/Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# host prediction\n",
    "\n",
    "mkdir iphop\n",
    "mkdir err log split_db results\n",
    "nano iphop_split.sh\n",
    "\n",
    "----------------------------\n",
    "\n",
    "#!/bin/bash\n",
    "#SBATCH -D /home/seuge91/blodgett_combined/iphop/\n",
    "#SBATCH --job-name=iphop_split\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH -t 1:00:00\n",
    "#SBATCH --ntasks=1\n",
    "#SBATCH --partition=bmm\n",
    "\n",
    "# for calculating the amount of time the job takes\n",
    "begin=`date +%s`\n",
    "echo $HOSTNAME\n",
    "\n",
    "source /home/csantosm/initconda\n",
    "conda activate IPHOP\n",
    "\n",
    "set=${1}\n",
    "\n",
    "full_db=/home/seuge91/blodgett_combined/bowtie/clustered_all.fa\n",
    "split_db=/home/seuge91/blodgett_combined/iphop/split_db\n",
    "\n",
    "iphop split --input_file ${full_db} --split_dir ${split_db}\n",
    "\n",
    "#getting end time to calculate time elapsed\n",
    "end=`date +%s`\n",
    "elapsed=`expr $end - $begin`\n",
    "echo Time taken: $elapsed\n",
    "\n",
    "----------------------------\n",
    "\n",
    "sbatch --output=./log/iphop_split.log --error=./err/iphop_split.err iphop_split.sh\n",
    "\n",
    "nano iphop_predict.sh\n",
    "\n",
    "----------------------------\n",
    "\n",
    "#!/bin/bash\n",
    "#SBATCH -D /home/seuge91/blodgett_combined/iphop/\n",
    "#SBATCH --job-name=iphop_predict\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH -t 24:00:00\n",
    "#SBATCH --mem=128GB\n",
    "#SBATCH --ntasks=24\n",
    "#SBATCH --partition=bmm\n",
    "\n",
    "# for calculating the amount of time the job takes\n",
    "begin=`date +%s`\n",
    "echo $HOSTNAME\n",
    "\n",
    "source /home/csantosm/initconda\n",
    "conda activate IPHOP\n",
    "\n",
    "batch=${1}\n",
    "\n",
    "iphop_db=/home/csantosm/databases/IPHOP_db/Sept_2021_pub\n",
    "\n",
    "cd /home/seuge91/blodgett_combined/iphop\n",
    "\n",
    "iphop predict --fa_file ./split_db/${batch}.fna --out_dir ./results/${batch} --db_dir ${iphop_db} --num_threads 24\n",
    "\n",
    "#getting end time to calculate time elapsed\n",
    "end=`date +%s`\n",
    "elapsed=`expr $end - $begin`\n",
    "echo Time taken: $elapsed\n",
    "    \n",
    "----------------------------\n",
    "\n",
    "\n",
    "batches=\"batch_00000 batch_00001 batch_00002 batch_00003 batch_00004 batch_00005 batch_00006 batch_00007 batch_00008 batch_00009 batch_00010 batch_00011 batch_00012 batch_00013 batch_00014 batch_00015 batch_00016 batch_00017 batch_00018 batch_00019 batch_00020 batch_00021 batch_00022 batch_00023 batch_00024 batch_00025 batch_00026 batch_00027 batch_00028 batch_00029 batch_00030 batch_00031 batch_00032 batch_00033 batch_00034 batch_00035 batch_00036 batch_00037 batch_00038 batch_00039 batch_00040 batch_00041 batch_00042 batch_00043 batch_00044 batch_00045 batch_00046 batch_00047 batch_00048 batch_00049 batch_00050 batch_00051 batch_00052 batch_00053 batch_00054 batch_00055 batch_00056 batch_00057 batch_00058 batch_00059 batch_00060 batch_00061 batch_00062 batch_00063 batch_00064 batch_00065 batch_00066 batch_00067 batch_00068 batch_00069 batch_00070 batch_00071 batch_00072 batch_00073 batch_00074 batch_00075 batch_00076 batch_00077 batch_00078 batch_00079 batch_00080 batch_00081 batch_00082 batch_00083 batch_00084 batch_00085 batch_00086 batch_00087 batch_00088 batch_00089 batch_00090 batch_00091 batch_00092 batch_00093 batch_00094 batch_00095 batch_00096 batch_00097 batch_00098 batch_00099 batch_00100 batch_00101 batch_00102 batch_00103 batch_00104 batch_00105 batch_00106 batch_00107 batch_00108 batch_00109 batch_00110 batch_00111 batch_00112 batch_00113 batch_00114 batch_00115 batch_00116 batch_00117 batch_00118 batch_00119 batch_00120 batch_00121 batch_00122 batch_00123 batch_00124 batch_00125 batch_00126 batch_00127 batch_00128 batch_00129 batch_00130 batch_00131 batch_00132 batch_00133 batch_00134 batch_00135 batch_00136 batch_00137 batch_00138 batch_00139 batch_00140 batch_00141 batch_00142 batch_00143 batch_00144 batch_00145 batch_00146 batch_00147 batch_00148 batch_00149 batch_00150 batch_00151 batch_00152 batch_00153 batch_00154 batch_00155 batch_00156 batch_00157 batch_00158 batch_00159 batch_00160 batch_00161 batch_00162 batch_00163 batch_00164 batch_00165 batch_00166 batch_00167 batch_00168 batch_00169 batch_00170 batch_00171 batch_00172 batch_00173 batch_00174 batch_00175 batch_00176 batch_00177 batch_00178 batch_00179 batch_00180 batch_00181 batch_00182 batch_00183 batch_00184 batch_00185 batch_00186 batch_00187 batch_00188 batch_00189 batch_00190 batch_00191 batch_00192 batch_00193 batch_00194 batch_00195 batch_00196 batch_00197 batch_00198 batch_00199 batch_00200 batch_00201 batch_00202 batch_00203 batch_00204 batch_00205 batch_00206 batch_00207 batch_00208 batch_00209 batch_00210 batch_00211 batch_00212 batch_00213 batch_00214 batch_00215 batch_00216 batch_00217 batch_00218 batch_00219 batch_00220 batch_00221 batch_00222 batch_00223 batch_00224 batch_00225 batch_00226 batch_00227 batch_00228 batch_00229 batch_00230 batch_00231 batch_00232 batch_00233 batch_00234 batch_00235 batch_00236 batch_00237 batch_00238 batch_00239 batch_00240 batch_00241 batch_00242 batch_00243 batch_00244 batch_00245 batch_00246 batch_00247 batch_00248 batch_00249 batch_00250 batch_00251 batch_00252 batch_00253 batch_00254 batch_00255 batch_00256 batch_00257 batch_00258 batch_00259 batch_00260 batch_00261 batch_00262 batch_00263 batch_00264 batch_00265 batch_00266 batch_00267 batch_00268 batch_00269 batch_00270 batch_00271 batch_00272\"\n",
    "for batch in $batches\n",
    "do\n",
    "sbatch --output=./log/${batch}.log --error=./err/${batch}.err iphop_predict.sh $batch\n",
    "done\n",
    "\n",
    "batches=\"batch_00087 batch_00077 batch_00073\"\n",
    "for batch in $batches\n",
    "do\n",
    "sbatch --output=./log/${batch}.log --error=./err/${batch}.err iphop_predict.sh $batch\n",
    "done\n",
    "\n",
    "# combine results from batches\n",
    "# get header from one of the batches\n",
    "cd results\n",
    "cd batch_00000\n",
    "head -n 1 Host_prediction_to_genome_m90.csv > all_Host_prediction_to_genome_m90.csv\n",
    "head -n 1 Host_prediction_to_genus_m90.csv > all_Host_prediction_to_genus_m90.csv\n",
    "head -n 10 Detailed_output_by_tool.csv > all_Detailed_output_by_tool.csv\n",
    "# move files up a folder\n",
    "mv all_Host_prediction_to_genome_m90.csv ..\n",
    "mv all_Host_prediction_to_genus_m90.csv ..\n",
    "mv all_Detailed_output_by_tool.csv ..\n",
    "# get body of each batch and concatenate to main file\n",
    "cd ../\n",
    "tail -n +2 -q batch_*/Host_prediction_to_genome_m90.csv >> all_Host_prediction_to_genome_m90.csv\n",
    "tail -n +2 -q batch_*/Host_prediction_to_genus_m90.csv >> all_Host_prediction_to_genus_m90.csv\n",
    "tail -n +11 batch_*/Detailed_output_by_tool.csv >> all_Detailed_output_by_tool.csv\n",
    "\n",
    "# download files\n",
    "scp seuge91@farm.cse.ucdavis.edu:/home/seuge91/blodgett_combined/iphop/results/*.csv /mnt/c/Users/segeo/Downloads"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
